{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commonted out the below lines as the packages are already installed in the environment\n",
    "\n",
    "# !pip install timm\n",
    "# !pip install nibabel\n",
    "# !pip install nilearn\n",
    "# !pip install light-the-torch && ltt install torch\n",
    "#!pip install torchio\n",
    "\n",
    "import tensorflow as tf\n",
    "#for neuroimaging data\n",
    "import torchio as tio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import os\n",
    "import time\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using {torch.cuda.get_device_name()} for inference' if torch.cuda.is_available() else 'Using CPU for inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seed for reproducibility\n",
    "seed = 42\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# np.random.seed(seed)\n",
    "# cudnn.benchmark = False\n",
    "# cudnn.deterministic = True\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'Dataset'\n",
    "\n",
    "# List all subdirectories in the root directory\n",
    "subdirectories = [x[0] for x in os.walk(root_dir)]\n",
    "\n",
    "dataset = []\n",
    "\n",
    "# Iterate over the subdirectories\n",
    "for subdir in subdirectories:\n",
    "    # Check if the subdirectory contains 'anat' in its path\n",
    "    if 'anat' in subdir:\n",
    "        # List all files in the subdirectory\n",
    "        files = os.listdir(subdir)\n",
    "        # Iterate over the files\n",
    "        for file in files:\n",
    "            # Check if the file is a .nii.gz file\n",
    "            if file.endswith('.nii.gz'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                # Load the Nifti image using TorchIO\n",
    "                subject = tio.Subject(\n",
    "                    mri = tio.ScalarImage(file_path),\n",
    "                    id = int(os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(file_path)))).replace('sub-', ''))\n",
    "                )\n",
    "                dataset.append(subject)\n",
    "       \n",
    "\n",
    "# Print the number of images in the dataset\n",
    "print('Number of Images in Dataset: ' + str(len(dataset)))\n",
    "\n",
    "# print the path of the first image\n",
    "print('\\nFirst Image Path in Dataset: ')\n",
    "print(dataset[0].mri.path)\n",
    "print('ID:', dataset[0]['id'])\n",
    "\n",
    "print('\\nFirst Image Dimensions in Dataset: ')\n",
    "print(dataset[0].spatial_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a file named participants.tsv exists in the each of the subfolder under the root directory\n",
    "# If it exists, load the file and display the contents\n",
    "df = pd.DataFrame()\n",
    "for subdir in subdirectories:\n",
    "    if os.path.exists(os.path.join(subdir, 'participants.csv')):\n",
    "        print('Found participants.tsv in ' + subdir)\n",
    "        new_df = pd.read_csv(os.path.join(subdir, 'participants.csv'), sep=',', header=0)\n",
    "        new_df = new_df[['participant_id', 'age', 'gender', 'dx']]\n",
    "        df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign each row of the df to the corresponding subject in the dataset\n",
    "for subject in dataset:\n",
    "    subject_id = subject['id']\n",
    "    if subject_id not in df['participant_id'].values:\n",
    "        print(subject_id + ' dataframe does not have this subject_id')\n",
    "    subject['age'] = df.loc[df['participant_id'] == subject_id, 'age'].values[0]\n",
    "    subject['gender'] = df.loc[df['participant_id'] == subject_id, 'gender'].values[0]\n",
    "    subject['dx'] = df.loc[df['participant_id'] == subject_id, 'dx'].values[0]\n",
    "    if subject['dx'] != 'Typically Developing Children':\n",
    "        subject['dx'] = 1\n",
    "    else:\n",
    "        subject['dx'] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    tio.CropOrPad((164, 164, 164)),\n",
    "    tio.ZNormalization(masking_method=tio.ZNormalization.mean),\n",
    "    tio.RescaleIntensity((0, 1)),\n",
    "    tio.RandomAffine(),\n",
    "    #tio.RandomNoise(),\n",
    "    # tio.RandomMotion(),\n",
    "    # tio.RandomBiasField(),\n",
    "\n",
    "]\n",
    "transform = tio.Compose(transforms)\n",
    "subjects_dataset = tio.SubjectsDataset(dataset, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shows the preprocessed images\n",
    "for i in range(5):\n",
    "    subject = subjects_dataset[i]\n",
    "    image = subject['mri']\n",
    "    print('Subject ID:', subject['id'])\n",
    "    print('Age:', subject['age'])\n",
    "    print('Gender:', subject['gender'])\n",
    "    print('Diagnosis:', subject['dx'])\n",
    "    image.plot()\n",
    "    plt.show()\n",
    "    print(subjects_dataset[i]['mri'].spatial_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the torchio dataset into train/test with a 80/20 ratio\n",
    "n = len(subjects_dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val = n - n_train\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(subjects_dataset, [n_train, n_val])\n",
    "\n",
    "\n",
    "# Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=3)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, num_workers=3)\n",
    "\n",
    "# print the number of batches in the train and validation loaders\n",
    "print('Number of batches in the train loader: ' + str(len(train_loader)))\n",
    "print('Number of batches in the validation loader: ' + str(len(val_loader)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained CNN model for neuorimaging data\n",
    "model = torchvision.models.video.r3d_18(pretrained=True)\n",
    "\n",
    "# Modify the first layer to accept 1 channel\n",
    "model.stem[0] = nn.Conv3d(1, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
    "\n",
    "# Adds regularization in all sequential layers\n",
    "# # for layer in model.modules():\n",
    "# #     if isinstance(layer, nn.Conv3d):\n",
    "# #         nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "# #     elif isinstance(layer, nn.BatchNorm3d):\n",
    "# #         nn.init.constant_(layer.weight, 1)\n",
    "# #         nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "\n",
    "\n",
    "# Modify the fully connected layer\n",
    "model.fc = nn.Linear(512, 2)\n",
    "\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(512, 256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(0.4),\n",
    "#     nn.Linear(256, 2)\n",
    "# )\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "model = model.to(device)\n",
    "print(torch.cuda.get_device_name())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# LOSS FUNCTION  \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterions = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# OPTIMIZERS\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# SCHEDULER\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.01)\n",
    "epochs = 5\n",
    "\n",
    "\n",
    "print('Training Started')\n",
    "\n",
    "# TRAINING LOOP\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        print('Batch: ' + str(i))\n",
    "        inputs = batch['mri']['data'].to(device)\n",
    "        labels = batch['dx'].to(device)\n",
    "        with autocast():   \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        print('Average Loss: ' + str(running_loss / (i + 1)))\n",
    "        optimizer.zero_grad()    \n",
    "\n",
    "    print('Epoch: ' + str(epoch + 1) + ', Loss: ' + str(running_loss / len(train_loader)))\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        inputs = batch['mri']['data'].to(device)\n",
    "        labels = batch['dx'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy: %.2f %%' % (100 * correct / total))\n",
    "print('Loss: ' + str(running_loss / len(val_loader)))\n",
    "\n",
    "# Get current time\n",
    "current_time = time.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "# Save the model with timestamp\n",
    "torch.save(model.state_dict(), 'model_' + current_time + '.pth')\n",
    "print('Model saved as model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Checkpoint\n",
    "checkpoint = {\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "}\n",
    "torch.save(checkpoint, 'checkpoint.pth')\n",
    "\n",
    "print('Checkpoint saved as checkpoint.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
