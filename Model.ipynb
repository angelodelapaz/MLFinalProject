{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commonted out the below lines as the packages are already installed in the environment\n",
    "\n",
    "#!pip install timm\n",
    "#!pip install nibabel\n",
    "#!pip install nilearn\n",
    "\n",
    "import tensorflow as tf\n",
    "#for neuroimaging data\n",
    "import nibabel as nib\n",
    "import nilearn as nilearn\n",
    "import timm as timm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using {torch.cuda.get_device_name()} for inference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "root_dir = 'brown'\n",
    "\n",
    "# List all subdirectories in the root directory\n",
    "subdirectories = [x[0] for x in os.walk(root_dir)]\n",
    "\n",
    "dataset = []\n",
    "\n",
    "# Iterate over the subdirectories\n",
    "for subdir in subdirectories:\n",
    "    # Check if the subdirectory contains 'anat' in its path\n",
    "    if 'anat' in subdir:\n",
    "        # List all files in the subdirectory\n",
    "        files = os.listdir(subdir)\n",
    "        # Iterate over the files\n",
    "        for file in files:\n",
    "            # Check if the file is a .nii.gz file\n",
    "            if file.endswith('.nii.gz'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                # Load the Nifti image\n",
    "                data = nib.load(file_path)\n",
    "                # Append the image data to the dataset\n",
    "                dataset.append(data)\n",
    "         \n",
    "# Print the number of images in the dataset\n",
    "print('Number of Images in Dataset: ' + str(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access data array and metadata\n",
    "data = dataset[22].get_fdata()\n",
    "affine = dataset[22].affine \n",
    "header = dataset[22].header\n",
    "\n",
    "# Display basic information\n",
    "print(f'Image dimensions: {data.shape}')\n",
    "print(f'Voxel dimensions: {header.get_zooms()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "\n",
    "plt.imshow(data[:, :, 90], cmap='gray')\n",
    "plt.axis('on')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the dataset\n",
    "\n",
    "from nilearn.image import resample_img\n",
    "\n",
    "# Define the target voxel dimensions\n",
    "target_voxel_dimensions = (1.0, 1.0, 1.0)\n",
    "\n",
    "# Resample the dataset to the target voxel dimensions\n",
    "resampled_dataset = []\n",
    "for data in dataset:\n",
    "    resampled_data = resample_img(data, target_affine=np.diag(target_voxel_dimensions))\n",
    "    resampled_dataset.append(resampled_data)\n",
    "\n",
    "# Display the resampled image\n",
    "resampled_data = resampled_dataset[22].get_fdata()\n",
    "plt.imshow(resampled_data[:, :, 90], cmap='gray')\n",
    "plt.axis('on')\n",
    "\n",
    "# Load the labels\n",
    "labels = pd.read_csv('brown/participants.tsv')\n",
    "labels.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Pre-Trained ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.video import r3d_18\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = r3d_18(pretrained=True)\n",
    "\n",
    "# Modify the last layer\n",
    "num_classes = 2  # replace with the number of classes in your dataset\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Print the model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split the dataset into training and validation sets\n",
    "# train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Print the number of images in the training and validation sets\n",
    "# print('Number of Images in Training Set: ' + str(len(train_dataset)))\n",
    "# print('Number of Images in Validation Set: ' + str(len(val_dataset)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
